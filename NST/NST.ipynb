{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ee0c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import copy\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "imsize = 512 if torch.cuda.is_available() else 128\n",
    "print(imsize)\n",
    "\n",
    "# Image loader\n",
    "loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image.to(device, torch.float)\n",
    "\n",
    "# Load images\n",
    "image_directory = \"images/\"\n",
    "style_img = image_loader(image_directory + \"dancing.jpg\")\n",
    "content_img = image_loader(image_directory + \"bhoomija.jpg\")\n",
    "assert style_img.size() == content_img.size(), \"Style and content images must be the same size\"\n",
    "\n",
    "# Image display\n",
    "unloader = transforms.ToPILImage()\n",
    "plt.ion()\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone().squeeze(0)\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "plt.figure()\n",
    "imshow(style_img, title='Style Image')\n",
    "plt.figure()\n",
    "imshow(content_img, title='Content Image')\n",
    "\n",
    "# Content loss\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "    def forward(self, input):\n",
    "        self.loss = F.mse_loss(input, self.target)\n",
    "        return input\n",
    "\n",
    "# Gram matrix\n",
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()\n",
    "    features = input.view(a * b, c * d)\n",
    "    G = torch.mm(features, features.t())\n",
    "    return G.div(a * b * c * d)\n",
    "\n",
    "# Style loss\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = F.mse_loss(G, self.target)\n",
    "        return input\n",
    "\n",
    "# Load VGG-19\n",
    "cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
    "cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "\n",
    "# Normalization module\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
    "        self.std = torch.tensor(std).view(-1, 1, 1)\n",
    "    def forward(self, img):\n",
    "        return (img - self.mean) / self.std\n",
    "\n",
    "# Model and loss setup\n",
    "content_layers_default = ['conv_4']\n",
    "style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
    "                               style_img, content_img,\n",
    "                               content_layers=content_layers_default,\n",
    "                               style_layers=style_layers_default):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "    normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "    model = nn.Sequential(normalization)\n",
    "    i = 0\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
    "        model.add_module(name, layer)\n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    "    model = model[:(i + 1)]\n",
    "    return model, style_losses, content_losses\n",
    "\n",
    "# Input image\n",
    "input_img = content_img.clone()\n",
    "plt.figure()\n",
    "imshow(input_img, title='Input Image')\n",
    "\n",
    "# Optimizer\n",
    "def get_input_optimizer(input_img):\n",
    "    optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
    "    return optimizer\n",
    "\n",
    "# Modified style transfer with loss and image tracking\n",
    "def run_style_transfer(cnn, normalization_mean, normalization_std, content_img, style_img, input_img,\n",
    "                      num_steps=300, style_weight=1000000, content_weight=1, loss_threshold=0.1,\n",
    "                      display_interval=50):\n",
    "    \"\"\"Run the style transfer with intermediate displays, dynamic step adjustment, and loss tracking.\"\"\"\n",
    "    print('Building the style transfer model..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn, normalization_mean,\n",
    "                                                                    normalization_std, style_img, content_img)\n",
    "    optimizer = get_input_optimizer(input_img)\n",
    "\n",
    "    # Lists to store losses and images\n",
    "    style_losses_history = []\n",
    "    content_losses_history = []\n",
    "    total_losses_history = []\n",
    "    intermediate_images = []\n",
    "    epochs = []\n",
    "\n",
    "    print('Optimizing..')\n",
    "    run = [0]\n",
    "    plt.ion()\n",
    "    while run[0] <= num_steps:\n",
    "        def closure():\n",
    "            input_img.data.clamp_(0, 1)\n",
    "            optimizer.zero_grad()\n",
    "            model(input_img)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "            for sl in style_losses:\n",
    "                style_score += sl.loss\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.loss\n",
    "            style_score *= style_weight\n",
    "            content_score *= content_weight\n",
    "            loss = style_score + content_score\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % display_interval == 0:\n",
    "                # Store losses only at display intervals\n",
    "                style_losses_history.append(style_score.item())\n",
    "                content_losses_history.append(content_score.item())\n",
    "                total_losses_history.append(loss.item())\n",
    "                print(f\"run {run[0]}:\")\n",
    "                print(f'Style Loss: {style_score.item():.4f} Content Loss: {content_score.item():.4f}')\n",
    "                plt.figure()\n",
    "                imshow(input_img, title=f'Output Image at Step {run[0]}')\n",
    "                plt.pause(0.001)\n",
    "\n",
    "                # Store intermediate image\n",
    "                intermediate_images.append(input_img.cpu().clone())\n",
    "                epochs.append(run[0])\n",
    "\n",
    "                if loss.item() < loss_threshold:\n",
    "                    print(f\"Loss {loss.item():.4f} below threshold {loss_threshold}. Stopping early.\")\n",
    "                    return input_img, style_losses_history, content_losses_history, total_losses_history, intermediate_images, epochs\n",
    "\n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    input_img.data.clamp_(0, 1)\n",
    "    plt.figure()\n",
    "    imshow(input_img, title='Final Output Image')\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.show()\n",
    "\n",
    "    user_input = input(\"Is the output satisfactory? (y/n) If 'n', enter additional steps to run: \")\n",
    "    if user_input.lower().startswith('n'):\n",
    "        try:\n",
    "            additional_steps = int(user_input[1:].strip())\n",
    "            print(f\"Running for {additional_steps} additional steps...\")\n",
    "            input_img, style_losses_history_ext, content_losses_history_ext, total_losses_history_ext, intermediate_images_ext, epochs_ext = run_style_transfer(\n",
    "                cnn, normalization_mean, normalization_std, content_img, style_img, input_img,\n",
    "                num_steps=additional_steps, style_weight=style_weight, content_weight=content_weight,\n",
    "                loss_threshold=loss_threshold, display_interval=display_interval)\n",
    "            # Extend histories\n",
    "            style_losses_history.extend(style_losses_history_ext)\n",
    "            content_losses_history.extend(content_losses_history_ext)\n",
    "            total_losses_history.extend(total_losses_history_ext)\n",
    "            intermediate_images.extend(intermediate_images_ext)\n",
    "            epochs.extend([e + run[0] for e in epochs_ext])\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Exiting without additional steps.\")\n",
    "\n",
    "    return input_img, style_losses_history, content_losses_history, total_losses_history, intermediate_images, epochs\n",
    "\n",
    "# Visualization function\n",
    "def plot_losses_and_optimization(epochs, style_losses_history, content_losses_history, total_losses_history, loss_threshold):\n",
    "    \"\"\"Plot loss vs epochs and optimization progress.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot 1: Loss vs Epochs\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, style_losses_history, label='Style Loss', color='blue')\n",
    "    plt.plot(epochs, content_losses_history, label='Content Loss', color='green')\n",
    "    plt.plot(epochs, total_losses_history, label='Total Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 2: Optimization Plot (Total Loss with Annotations)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, total_losses_history, label='Total Loss', color='red')\n",
    "    plt.axhline(y=loss_threshold, color='gray', linestyle='--', label=f'Loss Threshold ({loss_threshold})')\n",
    "    \n",
    "    # Annotate key points (e.g., where loss crosses threshold)\n",
    "    for i, loss in enumerate(total_losses_history):\n",
    "        if i < len(epochs) and loss < loss_threshold:\n",
    "            plt.annotate(f'Epoch {epochs[i]}\\nLoss {loss:.2f}',\n",
    "                         xy=(epochs[i], loss), xytext=(epochs[i], loss + loss_threshold * 0.1),\n",
    "                         arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "            break\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.title('Optimization Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the style transfer\n",
    "output, style_losses_history, content_losses_history, total_losses_history, intermediate_images, epochs = run_style_transfer(\n",
    "    cnn, cnn_normalization_mean, cnn_normalization_std, content_img, style_img, input_img, num_steps=3000)\n",
    "\n",
    "# Generate visualization\n",
    "plot_losses_and_optimization(epochs, style_losses_history, content_losses_history, total_losses_history, loss_threshold=0.1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
